{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from paddle import nn\n",
    "from PIL import Image\n",
    "from paddle.distributed import fleet, get_rank\n",
    "from visualdl import LogWriter\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 4\n",
    "EPOCH_NUM = 1\n",
    "logwriter = LogWriter(logdir='./runs')\n",
    "\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集\n",
    "class MyDataset(paddle.io.Dataset):\n",
    "    def __init__(self, img_dir='data/PALM-Training400/', csv_dir='data/Classification.csv') -> None:\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.csvfile = pd.read_csv(csv_dir)\n",
    "        self.imgpath = img_dir\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        return len(self.csvfile)\n",
    "    def __getitem__(self, idx):\n",
    "        img = np.reshape((np.array(Image.open(self.imgpath+os.sep+self.csvfile['imgName'][idx]).resize((IMAGE_SIZE,IMAGE_SIZE))).astype('float32')),(3,IMAGE_SIZE,IMAGE_SIZE))/256.\n",
    "        lab = np.array(self.csvfile['Label'][idx])\n",
    "        return img,lab\n",
    "    pass\n",
    "mydataset = MyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0203 11:41:02.579298 96492 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 11.7\n",
      "W0203 11:41:02.586143 96492 gpu_resources.cc:91] device: 0, cuDNN Version: 8.7.\n"
     ]
    }
   ],
   "source": [
    "# 定义网络结构\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    net = [nn.Conv2D(in_channels=in_channels,out_channels=out_channels,kernel_size=3,padding=1),nn.ReLU()]\n",
    "    for i in range(num_convs-1):\n",
    "        net.append(nn.Conv2D(out_channels=out_channels,in_channels=out_channels,kernel_size=3,stride=1,padding=1))\n",
    "        net.append(nn.ReLU())\n",
    "    net.append(nn.MaxPool2D(kernel_size=2))\n",
    "    return nn.Sequential(*net)\n",
    "\n",
    "def vgg_stack(num_convs,channels):\n",
    "    net = []\n",
    "    for n,c in zip(num_convs,channels):\n",
    "        in_c = c[0]\n",
    "        out_c = c[1]\n",
    "        net.append(vgg_block(n,in_c,out_c))\n",
    "    return nn.Sequential(*net)\n",
    "\n",
    "class VGG(paddle.nn.Layer):\n",
    "    def __init__(self,vgg_net) -> None:\n",
    "        super(VGG,self).__init__()\n",
    "        self.conv = vgg_stack(vgg_net[0],vgg_net[1])\n",
    "        self.line = nn.Sequential(\n",
    "            nn.Linear(512*7*7,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = paddle.flatten(x, 1, -1)\n",
    "        x = self.line(x)\n",
    "        return x\n",
    "\n",
    "net=VGG([[2,2,3,3,3], [[3,64],[64,128],[128,256],[256,512],[512,512]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0203 11:44:38.599725 98711 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 11.7\n",
      "W0203 11:44:38.608122 98711 gpu_resources.cc:91] device: 0, cuDNN Version: 8.7.\n"
     ]
    }
   ],
   "source": [
    "from paddle.nn import Conv2D, MaxPool2D\n",
    "\n",
    "class VGG(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "\n",
    "        in_channels = [3, 64, 128, 256, 512, 512]\n",
    "        # 定义第一个block，包含两个卷积\n",
    "        self.conv1_1 = Conv2D(in_channels=in_channels[0], out_channels=in_channels[1], kernel_size=3, padding=1, stride=1)\n",
    "        self.conv1_2 = Conv2D(in_channels=in_channels[1], out_channels=in_channels[1], kernel_size=3, padding=1, stride=1)\n",
    "        # 定义第二个block，包含两个卷积\n",
    "        self.conv2_1 = Conv2D(in_channels=in_channels[1], out_channels=in_channels[2], kernel_size=3, padding=1, stride=1)\n",
    "        self.conv2_2 = Conv2D(in_channels=in_channels[2], out_channels=in_channels[2], kernel_size=3, padding=1, stride=1)\n",
    "        # 定义第三个block，包含三个卷积\n",
    "        self.conv3_1 = Conv2D(in_channels=in_channels[2], out_channels=in_channels[3], kernel_size=3, padding=1, stride=1)\n",
    "        self.conv3_2 = Conv2D(in_channels=in_channels[3], out_channels=in_channels[3], kernel_size=3, padding=1, stride=1)\n",
    "        self.conv3_3 = Conv2D(in_channels=in_channels[3], out_channels=in_channels[3], kernel_size=3, padding=1, stride=1)\n",
    "        # 定义第四个block，包含三个卷积\n",
    "        self.conv4_1 = Conv2D(in_channels=in_channels[3], out_channels=in_channels[4], kernel_size=3, padding=1, stride=1)\n",
    "        self.conv4_2 = Conv2D(in_channels=in_channels[4], out_channels=in_channels[4], kernel_size=3, padding=1, stride=1)\n",
    "        self.conv4_3 = Conv2D(in_channels=in_channels[4], out_channels=in_channels[4], kernel_size=3, padding=1, stride=1)\n",
    "        # 定义第五个block，包含三个卷积\n",
    "        self.conv5_1 = Conv2D(in_channels=in_channels[4], out_channels=in_channels[5], kernel_size=3, padding=1, stride=1)\n",
    "        self.conv5_2 = Conv2D(in_channels=in_channels[5], out_channels=in_channels[5], kernel_size=3, padding=1, stride=1)\n",
    "        self.conv5_3 = Conv2D(in_channels=in_channels[5], out_channels=in_channels[5], kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        # 使用Sequential 将全连接层和relu组成一个线性结构（fc + relu）\n",
    "        # 当输入为224x224时，经过五个卷积块和池化层后，特征维度变为[512x7x7]\n",
    "        self.fc1 = paddle.nn.Sequential(paddle.nn.Linear(512 * 7 * 7, 4096), paddle.nn.ReLU())\n",
    "        self.drop1_ratio = 0.5\n",
    "        self.dropout1 = paddle.nn.Dropout(self.drop1_ratio, mode='upscale_in_train')\n",
    "        # 使用Sequential 将全连接层和relu组成一个线性结构（fc + relu）\n",
    "        self.fc2 = paddle.nn.Sequential(paddle.nn.Linear(4096, 4096), paddle.nn.ReLU())\n",
    "\n",
    "        self.drop2_ratio = 0.5\n",
    "        self.dropout2 = paddle.nn.Dropout(self.drop2_ratio, mode='upscale_in_train')\n",
    "        self.fc3 = paddle.nn.Linear(4096, 1)\n",
    "\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "        self.pool = MaxPool2D(stride=2, kernel_size=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1_1(x))\n",
    "        x = self.relu(self.conv1_2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu(self.conv2_1(x))\n",
    "        x = self.relu(self.conv2_2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu(self.conv3_1(x))\n",
    "        x = self.relu(self.conv3_2(x))\n",
    "        x = self.relu(self.conv3_3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu(self.conv4_1(x))\n",
    "        x = self.relu(self.conv4_2(x))\n",
    "        x = self.relu(self.conv4_3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu(self.conv5_1(x))\n",
    "        x = self.relu(self.conv5_2(x))\n",
    "        x = self.relu(self.conv5_3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = paddle.flatten(x, 1, -1)\n",
    "        x = self.dropout1(self.relu(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    pass\n",
    "net = VGG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,opt,dataset,epoch,batch,logwriter):\n",
    "    for epoch_id in range(epoch):\n",
    "        model.train()\n",
    "        train_loader = paddle.io.DataLoader(dataset,shuffle=True,drop_last=True,batch_size=batch)\n",
    "        train_batchs_per_epoch = len(train_loader)\n",
    "        for batch_id, data in enumerate(train_loader):\n",
    "            #准备数据\n",
    "            images, labels = data\n",
    "\n",
    "            #前向计算的过程\n",
    "            predicts = model(images)\n",
    "\n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            #记录当前训练 Loss 到 VisualDL\n",
    "            logwriter.add_scalar(\"train_avg_loss\", value=avg_loss.numpy(), step=batch_id+epoch_id*(train_batchs_per_epoch))\n",
    "\n",
    "            #每训练了 20 批次的数据，打印下当前 Loss 的情况\n",
    "            if batch_id % 20 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "\n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            # 最小化 loss,更新参数\n",
    "            opt.step()\n",
    "            # 清除梯度\n",
    "            opt.clear_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pm(model, optimizer):\n",
    "    # 开启0号GPU训练\n",
    "    use_gpu = True\n",
    "    paddle.device.set_device('gpu:0') if use_gpu else paddle.device.set_device('cpu')\n",
    "\n",
    "    print('start training ... ')\n",
    "    model.train()\n",
    "    # 定义数据读取器，训练数据读取器和验证数据读取器\n",
    "    train_loader = paddle.io.DataLoader(mydataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "    valid_loader = paddle.io.DataLoader(mydataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            print('\\r{}'.format(batch_id),end='')\n",
    "            x_data, y_data = data\n",
    "            img = paddle.to_tensor(x_data)\n",
    "            label = paddle.to_tensor(y_data)\n",
    "            # 运行模型前向计算，得到预测值\n",
    "            logits = model(img)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 20 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {:.4f}\".format(epoch, batch_id, float(avg_loss.numpy())))\n",
    "            # 反向传播，更新权重，清除梯度\n",
    "            avg_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "        model.eval()\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        for batch_id, data in enumerate(valid_loader()):\n",
    "            x_data, y_data = data\n",
    "            img = paddle.to_tensor(x_data)\n",
    "            label = paddle.to_tensor(y_data)\n",
    "            # 运行模型前向计算，得到预测值\n",
    "            logits = model(img)\n",
    "            # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "            # 计算sigmoid后的预测概率，进行loss计算\n",
    "            pred = F.sigmoid(logits)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label)\n",
    "            # 计算预测概率小于0.5的类别\n",
    "            pred2 = pred * (-1.0) + 1.0\n",
    "            # 得到两个类别的预测概率，并沿第一个维度级联\n",
    "            pred = paddle.concat([pred2, pred], axis=1)\n",
    "            acc = paddle.metric.accuracy(pred, paddle.cast(label, dtype='int64'))\n",
    "\n",
    "            accuracies.append(acc.numpy())\n",
    "            losses.append(loss.numpy())\n",
    "        print(\"[validation] accuracy/loss: {:.4f}/{:.4f}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "        model.train()\n",
    "\n",
    "        paddle.save(model.state_dict(), 'palm.pdparams')\n",
    "        paddle.save(optimizer.state_dict(), 'palm.pdopt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 创建模型\n",
    "model = VGG()\n",
    "# opt = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "opt = paddle.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameters=model.parameters())\n",
    "\n",
    "# 启动训练过程\n",
    "train_pm(model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.2109375 , 0.12109375, 0.3671875 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.21484375,\n",
       "          0.52734375, 0.3515625 ],\n",
       "         [0.20703125, 0.5234375 , 0.34765625, ..., 0.19921875,\n",
       "          0.11328125, 0.37109375]],\n",
       " \n",
       "        [[0.20703125, 0.1171875 , 0.35546875, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.20703125,\n",
       "          0.53125   , 0.35546875],\n",
       "         [0.21484375, 0.515625  , 0.34765625, ..., 0.17578125,\n",
       "          0.10546875, 0.390625  ],\n",
       "         ...,\n",
       "         [0.1484375 , 0.54296875, 0.28515625, ..., 0.21484375,\n",
       "          0.11328125, 0.33984375],\n",
       "         [0.2109375 , 0.10546875, 0.33984375, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.15625   ,\n",
       "          0.5234375 , 0.29296875]],\n",
       " \n",
       "        [[0.15234375, 0.53125   , 0.2890625 , ..., 0.22265625,\n",
       "          0.12109375, 0.33984375],\n",
       "         [0.21875   , 0.12109375, 0.33984375, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.15234375,\n",
       "          0.50390625, 0.2890625 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]]], dtype=float32),\n",
       " array(0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74870/3797923749.py:1: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(mydataset)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'MyDataset' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mshuffle(mydataset)\n",
      "File \u001b[0;32mmtrand.pyx:4570\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mmtrand.pyx:4573\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'MyDataset' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(mydataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec69b73d0a6985895cc9f85863fd33c600647e90f46968e0f1901acb27b9505b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
