{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T13:58:46.925735Z",
     "iopub.status.busy": "2023-02-04T13:58:46.925057Z",
     "iopub.status.idle": "2023-02-04T13:58:48.803973Z",
     "shell.execute_reply": "2023-02-04T13:58:48.802867Z",
     "shell.execute_reply.started": "2023-02-04T13:58:46.925684Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\r\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from paddle import nn\n",
    "from PIL import Image\n",
    "from paddle.distributed import fleet, get_rank\n",
    "import copy\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_NUM = 5\n",
    "\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T13:58:48.806953Z",
     "iopub.status.busy": "2023-02-04T13:58:48.805929Z",
     "iopub.status.idle": "2023-02-04T13:58:48.815332Z",
     "shell.execute_reply": "2023-02-04T13:58:48.814525Z",
     "shell.execute_reply.started": "2023-02-04T13:58:48.806914Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义数据集\n",
    "class MyDataset(paddle.io.Dataset):\n",
    "    def __init__(self, img_dir='data/PALM-Training400/', csvfile=None, mode='train') -> None:\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.imgpath = img_dir\n",
    "        self.mode = mode\n",
    "        if self.mode=='test':\n",
    "            self.filedir = os.listdir(img_dir)\n",
    "        else:\n",
    "            self.csvfile = csvfile\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        if self.mode=='test':\n",
    "            return len(self.filedir)\n",
    "        else:\n",
    "            return len(self.csvfile)\n",
    "        pass\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode=='test':\n",
    "            img = np.reshape((np.array(Image.open(self.imgpath+os.sep+self.filedir[idx]).resize((IMAGE_SIZE,IMAGE_SIZE))).astype('float32')),(3,IMAGE_SIZE,IMAGE_SIZE))/256.\n",
    "            lab = self.filedir[idx]\n",
    "        else:\n",
    "            img = np.reshape((np.array(Image.open(self.imgpath+os.sep+self.csvfile['imgName'][idx]).resize((IMAGE_SIZE,IMAGE_SIZE))).astype('float32')),(3,IMAGE_SIZE,IMAGE_SIZE))/256.\n",
    "            lab = np.array(self.csvfile['Label'][idx]).astype('float32')\n",
    "        return img,lab\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T13:58:48.816738Z",
     "iopub.status.busy": "2023-02-04T13:58:48.816424Z",
     "iopub.status.idle": "2023-02-04T13:58:48.825409Z",
     "shell.execute_reply": "2023-02-04T13:58:48.824609Z",
     "shell.execute_reply.started": "2023-02-04T13:58:48.816712Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    net = [nn.Conv2D(in_channels=in_channels,out_channels=out_channels,kernel_size=3,padding=1),nn.ReLU()]\n",
    "    for i in range(num_convs-1):\n",
    "        net.append(nn.Conv2D(out_channels=out_channels,in_channels=out_channels,kernel_size=3,stride=1,padding=1))\n",
    "        net.append(nn.ReLU())\n",
    "    net.append(nn.MaxPool2D(kernel_size=2))\n",
    "    return nn.Sequential(*net)\n",
    "\n",
    "def vgg_stack(num_convs,channels):\n",
    "    net = []\n",
    "    for n,c in zip(num_convs,channels):\n",
    "        in_c = c[0]\n",
    "        out_c = c[1]\n",
    "        net.append(vgg_block(n,in_c,out_c))\n",
    "    return nn.Sequential(*net)\n",
    "\n",
    "class VGG(paddle.nn.Layer):\n",
    "    def __init__(self,vgg_net) -> None:\n",
    "        super(VGG,self).__init__()\n",
    "        self.conv = vgg_stack(vgg_net[0],vgg_net[1])\n",
    "        self.line = nn.Sequential(\n",
    "            nn.Linear(512*7*7,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = paddle.flatten(x, 1, -1)\n",
    "        x = self.line(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T14:00:36.749664Z",
     "iopub.status.busy": "2023-02-04T14:00:36.748943Z",
     "iopub.status.idle": "2023-02-04T14:00:36.760886Z",
     "shell.execute_reply": "2023-02-04T14:00:36.760002Z",
     "shell.execute_reply.started": "2023-02-04T14:00:36.749610Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_pm(model, optimizer, train_loader, valid_loader, epoches=1):\n",
    "    # 开启0号GPU训练\n",
    "    paddle.device.set_device('gpu:0')\n",
    "\n",
    "    print('start training ... ')\n",
    "    model.train()\n",
    "    # 定义数据读取器，训练数据读取器和验证数据读取器\n",
    "    # train_loader = paddle.io.DataLoader(mydataset,batch_size=BATCH_SIZE,shuffle=True,drop_last=True)\n",
    "    # valid_loader = paddle.io.DataLoader(mydataset,batch_size=BATCH_SIZE,shuffle=True,drop_last=True)\n",
    "    for epoch in range(epoches):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            x_data, y_data = data\n",
    "            img = paddle.to_tensor(x_data)\n",
    "            label = paddle.reshape(paddle.to_tensor(y_data),(-1,1))\n",
    "            # 运行模型前向计算，得到预测值\n",
    "            logits = model(img)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 5 == 4:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {:.4f}\".format(epoch, batch_id, float(avg_loss.numpy())))\n",
    "            # 反向传播，更新权重，清除梯度\n",
    "            avg_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "        model.eval()\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        for batch_id, data in enumerate(valid_loader()):\n",
    "            x_data, y_data = data\n",
    "            img = paddle.to_tensor(x_data)\n",
    "            label = paddle.reshape(paddle.to_tensor(y_data),(-1,1))\n",
    "            # 运行模型前向计算，得到预测值\n",
    "            logits = model(img)\n",
    "            # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "            # 计算sigmoid后的预测概率，进行loss计算\n",
    "            pred = F.sigmoid(logits)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label)\n",
    "            # 计算预测概率小于0.5的类别\n",
    "            pred2 = pred * (-1.0) + 1.0\n",
    "            # 得到两个类别的预测概率，并沿第一个维度级联\n",
    "            pred = paddle.concat([pred2, pred], axis=1)\n",
    "            acc = paddle.metric.accuracy(pred, paddle.cast(label, dtype='int64'))\n",
    "\n",
    "            accuracies.append(acc.numpy())\n",
    "            losses.append(loss.numpy())\n",
    "        print(\"[validation] accuracy/loss: {:.4f}/{:.4f}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "        model.train()\n",
    "\n",
    "        paddle.save(model.state_dict(), 'palmp{}_{}.pdparams'.format(epoch,acc.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T13:58:48.839028Z",
     "iopub.status.busy": "2023-02-04T13:58:48.838485Z",
     "iopub.status.idle": "2023-02-04T13:58:50.388671Z",
     "shell.execute_reply": "2023-02-04T13:58:50.387596Z",
     "shell.execute_reply.started": "2023-02-04T13:58:48.839002Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0204 21:58:48.843931 16076 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0204 21:58:48.848599 16076 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n"
     ]
    }
   ],
   "source": [
    "# 创建模型\n",
    "model =[VGG([[2,2,3,3,3], [[3,64],[64,128],[128,256],[256,512],[512,512]]]) for i in range(5)]\n",
    "# opt = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "opt = [paddle.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameters=model[i].parameters()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T14:00:38.734883Z",
     "iopub.status.busy": "2023-02-04T14:00:38.734225Z",
     "iopub.status.idle": "2023-02-04T14:06:42.366619Z",
     "shell.execute_reply": "2023-02-04T14:06:42.365474Z",
     "shell.execute_reply.started": "2023-02-04T14:00:38.734838Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \r\n",
      "epoch: 0, batch_id: 4, loss is: 0.4881\r\n",
      "epoch: 0, batch_id: 9, loss is: 0.5245\r\n",
      "epoch: 0, batch_id: 14, loss is: 0.5482\r\n",
      "epoch: 0, batch_id: 19, loss is: 0.2626\r\n",
      "[validation] accuracy/loss: 0.9625/0.2490\r\n",
      "start training ... \r\n",
      "epoch: 0, batch_id: 4, loss is: 0.7193\r\n",
      "epoch: 0, batch_id: 9, loss is: 0.7356\r\n",
      "epoch: 0, batch_id: 14, loss is: 0.5501\r\n",
      "epoch: 0, batch_id: 19, loss is: 0.3735\r\n",
      "[validation] accuracy/loss: 0.9000/0.4009\r\n",
      "start training ... \r\n",
      "epoch: 0, batch_id: 4, loss is: 0.7218\r\n",
      "epoch: 0, batch_id: 9, loss is: 0.7143\r\n",
      "epoch: 0, batch_id: 4, loss is: 0.6873\r\n",
      "epoch: 0, batch_id: 9, loss is: 0.7244\r\n",
      "epoch: 0, batch_id: 14, loss is: 0.5817\r\n",
      "epoch: 0, batch_id: 19, loss is: 0.5512\r\n",
      "[validation] accuracy/loss: 0.8125/0.4629\r\n",
      "start training ... \r\n",
      "epoch: 0, batch_id: 4, loss is: 0.8424\r\n",
      "epoch: 0, batch_id: 9, loss is: 0.6207\r\n",
      "epoch: 0, batch_id: 14, loss is: 0.5804\r\n",
      "epoch: 0, batch_id: 19, loss is: 0.5365\r\n",
      "[validation] accuracy/loss: 0.7563/0.5432\r\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Train/Classification.csv')\n",
    "for i in range(5):\n",
    "    valid_loader = paddle.io.DataLoader(\n",
    "        MyDataset('常规赛：PALM病理性近视预测/Train/fundus_image',(df[i*160:i*160+160]).reset_index()),\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    train_loader = paddle.io.DataLoader(\n",
    "        MyDataset('常规赛：PALM病理性近视预测/Train/fundus_image',pd.concat([df[:160*i],df[160*i+160:]]).reset_index()),\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    train_pm(model[i],opt[i],train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T14:08:45.737422Z",
     "iopub.status.busy": "2023-02-04T14:08:45.736795Z",
     "iopub.status.idle": "2023-02-04T14:08:45.743859Z",
     "shell.execute_reply": "2023-02-04T14:08:45.742853Z",
     "shell.execute_reply.started": "2023-02-04T14:08:45.737381Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    pred_list = np.array([])\n",
    "    file_list = np.array([])\n",
    "    for idx, data in enumerate(dataloader):\n",
    "        print('\\r{}/{}'.format(1+idx,len(dataloader)),end='')\n",
    "        x_data, filename = data\n",
    "        img = paddle.to_tensor(x_data)\n",
    "        # 运行模型前向计算，得到预测值\n",
    "        logits = model(img)\n",
    "        # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "        # 计算sigmoid后的预测概率，进行loss计算\n",
    "        pred = F.sigmoid(logits)\n",
    "        pred_list = np.append(pred_list, pred.numpy().ravel())\n",
    "        file_list = np.append(file_list, filename)\n",
    "    return pred_list, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T14:08:47.703032Z",
     "iopub.status.busy": "2023-02-04T14:08:47.701840Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "validset = paddle.io.DataLoader(\n",
    "    MyDataset('常规赛：PALM病理性近视预测/Train/fundus_image',df),\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "testdataset = MyDataset('PALM-Testing400-Images',None, 'test')\n",
    "testdataloader = paddle.io.DataLoader(testdataset,shuffle=False,drop_last=False,batch_size=BATCH_SIZE)\n",
    "for i in range(5):\n",
    "    pred_list,file_list = predict(model[i], validset)\n",
    "    pd.DataFrame(np.c_[file_list,pred_list],columns=['FileName','PM Risk']).to_csv('temp_{}.csv'.format(i),index=False)\n",
    "    pred_list,file_list = predict(model[i], testdataloader)\n",
    "    pd.DataFrame(np.c_[file_list,pred_list],columns=['FileName','PM Risk']).to_csv('pred_{}.csv'.format(i),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec69b73d0a6985895cc9f85863fd33c600647e90f46968e0f1901acb27b9505b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
